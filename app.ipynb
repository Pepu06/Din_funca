{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score\n\u001b[0;32m     15\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m ]\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyASfBmk76PK3hpBQ0Bjp_ACA3ineq53VvM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify \n",
    "import os\n",
    "import re\n",
    "import pypdf\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "import google.generativeai as palm\n",
    "import google.generativeai as genai\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from typing import List\n",
    "import speech_recognition as sr\n",
    "import json\n",
    "\n",
    "os.environ[ \"GEMINI_API_KEY\" ]= \"AIzaSyASfBmk76PK3hpBQ0Bjp_ACA3ineq53VvM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Reads the text content from a PDF file and returns it as a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The concatenated text content of all pages in the PDF.\n",
    "    \"\"\"\n",
    "    # Logic to read pdf\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    # Loop over each page and store it in a variable\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "# replace the path with your file path\n",
    "pdf_text = load_pdf(file_path=\"mati.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str):\n",
    "    \"\"\"\n",
    "    Splits a text string into a list of non-empty substrings based on the specified pattern.\n",
    "    The \"\\n \\n\" pattern will split the document para by para\n",
    "    Parameters:\n",
    "    - text (str): The input text to be split.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing non-empty substrings obtained by splitting the input text.\n",
    "\n",
    "    \"\"\"\n",
    "    split_text = re.split('\\n \\n', text)\n",
    "    return [i for i in split_text if i != \"\"]\n",
    "\n",
    "chunked_text = split_text(text=pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"\n",
    "    Custom embedding function using the Gemini AI API for document retrieval.\n",
    "\n",
    "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
    "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
    "\n",
    "    Parameters:\n",
    "    - input (Documents): A collection of documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - Embeddings: Embeddings generated for the input documents.\n",
    "    \"\"\"\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = \"models/embedding-001\"\n",
    "        title = \"Custom query\"\n",
    "        return genai.embed_content(model=model,\n",
    "                                   content=input,\n",
    "                                   task_type=\"retrieval_document\",\n",
    "                                   title=title)[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_db(documents:List, path:str, name:str):\n",
    "    \"\"\"\n",
    "    Creates a Chroma database using the provided documents, path, and collection name.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: An iterable of documents to be added to the Chroma database.\n",
    "    - path (str): The path where the Chroma database will be stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    for i, d in enumerate(documents):\n",
    "        db.add(documents=d, ids=str(i))\n",
    "\n",
    "    return db, name\n",
    "\n",
    "db,name =create_chroma_db(documents=chunked_text, \n",
    "                          path=\"RAG\", #replace with your path\n",
    "                          name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_collection(path, name):\n",
    "    \"\"\"\n",
    "    Loads an existing Chroma collection from the specified path with the given name.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The path where the Chroma database is stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - chromadb.Collection: The loaded Chroma Collection.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    return db\n",
    "\n",
    "db=load_chroma_collection(path=\"RAG1\", name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_passage(query, db, n_results):\n",
    "  passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "  return passage\n",
    "\n",
    "#Example usage\n",
    "relevant_text = get_relevant_passage(query=\"Intellykeys\",db=db,n_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escuchando...\n",
      "Texto reconocido: Hola Me llamo Pedro\n"
     ]
    }
   ],
   "source": [
    "def escuchar_mic():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Escuchando...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, phrase_time_limit=5)\n",
    "            texto = recognizer.recognize_google(audio, language=\"es-ES\")\n",
    "            print(f\"Texto reconocido: {texto}\")\n",
    "            return texto\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"No se pudo reconocer el audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error en la solicitud de reconocimiento: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_rag_prompt(query, texto_mic, relevant_passage):\n",
    "  escaped_passage = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  escaped_texto_mic = texto_mic.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = (\"\"\"You are a helpful SPANISH and knowledgeable assistant that helps complete text using the reference passage and microphone context included below. \\\n",
    "  Ensure your response is fluent, coherent, and relevant to the user's text, adding value and depth where appropriate. \\\n",
    "  You are assisting a general audience, so focus on clarity, providing thoughtful and well-structured continuations or expansions of the given text. Maintain a friendly, conversational tone. \\\n",
    "  Give considerable importance to the context provided by the microphone. Generate ALWAYS three options of the completed text for the user to choose from. Each one should be unique and different from the others and not much longer than the user's text. \\\n",
    "  If the passage does not provide relevant information, you may complete the user's text based on your understanding. \\\n",
    "  DO NOT FORGET TO INCLUDE THE USER TEXT IN THE BEGINNING OF THE COMPLETION. \\\n",
    "          \n",
    "  USER TEXT: '{query}'\n",
    "  PASSAGE: '{escaped_passage}'\n",
    "  MICROPHONE CONTEXT: '{escaped_texto_mic}'\n",
    "\n",
    "  COMPLETION:\n",
    "  \"\"\").format(query=query, escaped_passage=escaped_passage, escaped_texto_mic=escaped_texto_mic)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "def generate_answer_by_prompt(prompt):\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    answer = model.generate_content(prompt)\n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(db,query):\n",
    "    #retrieve top 3 relevant text chunks\n",
    "    texto_mic = escuchar_mic()\n",
    "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
    "    prompt = make_rag_prompt(query, \n",
    "                             texto_mic,\n",
    "                             relevant_passage=\"\".join(relevant_text)) # joining the relevant chunks to create a single passage\n",
    "    answer = generate_answer_by_prompt(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Hola Pedro!\n",
      "2. Hola Pedro, qu√© tal?\n",
      "3. Hola Pedro, mucho gusto.\n"
     ]
    }
   ],
   "source": [
    "db=load_chroma_collection(path=\"RAG\", #replace with path of your persistent directory\n",
    "                          name=\"rag_experiment\") #replace with the collection name\n",
    "\n",
    "answer = generate_answer(db,\"Hola, \")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
